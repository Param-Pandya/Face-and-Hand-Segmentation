# Face-and-Hand-Segmentation


### âœ… Download Instructions

Since you're unable to download directly, here's what you can do:

#### Option 1: **Copy-Paste Manually**

1. **Create a new file** named `README.md` in your project folder.
2. **Copy and paste** the following content into it:


```markdown
# ğŸ§  Face & Hand Segmentation using SAM2

This project performs **automated face and hand segmentation** in images using a combination of **YOLO + cvlib** for detection and **SAM2** (Segment Anything Model 2 via Replicate API) for fine-grained segmentation. A **Gradio web UI** is also included for quick testing.

> **ğŸ”§ Created by Param Pandya**  
> **ğŸ Requires: Python 3.10**

---

## ğŸ“¦ Features

- Detects **faces** using `cvlib` (OpenCV + DNN backend)
- Detects **hands** using **YOLOv8**
- Sends bounding boxes to **SAM2** (via Replicate API)
- Overlays the segmentation masks on the original image
- Includes **CLI** and **Web UI** (via Gradio)
- Fully automated â€” no manual input required

---

## ğŸ“ Project Structure

```plaintext
.
â”œâ”€â”€ app.py                  # Gradio UI
â”œâ”€â”€ main.py                 # CLI pipeline
â”œâ”€â”€ detect_yolo_cvlib.py    # Face & hand detection
â”œâ”€â”€ sam2_infer.py           # Calls SAM2 API (Replicate)
â”œâ”€â”€ visualize.py            # Overlays masks on the image
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ input/                  # Input image directory
â”œâ”€â”€ sample_outputs/         # Output images with segmentation
â””â”€â”€ .env                    # Your API key (not committed)
```

---

## ğŸ”§ Setup

### âœ… Prerequisites

- Python 3.10
- Replicate API Key: Get one from https://replicate.com/account/api-tokens

### ğŸ›  Installation

```bash
# Clone the repo
git clone https://github.com/your-username/face-hand-segmentation-sam2.git
cd face-hand-segmentation-sam2

# Create virtual environment (recommended)
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\\Scripts\\activate

# Install dependencies
pip install -r requirements.txt
````

### ğŸ” Configure API Key

Create a `.env` file in the root folder:

```
REPLICATE_API_TOKEN=your_replicate_api_token
```

---

## ğŸš€ Usage

### 1. Command-Line Interface (CLI)

Process an image via the command line:

```bash
python main.py
```

> âœï¸ Make sure to place your test image in `input/` and update the filename in `main.py`.

### 2. Gradio Web UI

Launch an interactive browser app:

```bash
python app.py
```

Upload an image and view segmented output instantly.

---

## ğŸ§  How It Works

1. **Detection**
   Uses `cvlib` for **face detection** and **YOLOv8** (via `ultralytics`) for **hand detection**.

2. **Segmentation (SAM2)**
   The bounding boxes are sent to Replicate's **SAM2 model**, which returns segmentation masks.

3. **Visualization**
   The masks are downloaded and overlaid on the original image using OpenCV and Matplotlib.

---

## âš ï¸ Known Limitations

* ğŸ§¤ Hand detection might miss occluded or partially visible hands.
* ğŸ‘¥ Works best for images with 1â€“2 subjects; batch processing not yet optimized.
* ğŸŒ Performance depends on network/API response from Replicate.

---

## âœ… Requirements

See `requirements.txt` or install via:

```bash
pip install -r requirements.txt
```

Main libraries used:

* `cvlib`, `opencv-python`
* `ultralytics` (YOLOv8)
* `replicate`, `python-dotenv`
* `matplotlib`, `gradio`

---

## ğŸ‘¤ Author

**Param Pandya**
ğŸ“ [GitHub](https://github.com/param-pandya)
ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/param-pandya)

---

## ğŸ“ License

This project is licensed under the [MIT License](LICENSE) â€“ free to use and modify.

